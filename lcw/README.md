# Long Context Window

## Links
* DeepSpeed-Ulysses: https://www.deepspeed.ai/tutorials/ds-sequence/ + Paper: https://arxiv.org/pdf/2309.14509
* Qwen2.5-1M: https://qwenlm.github.io/blog/qwen2.5-1m/
* [Princeton long-context language models](https://github.com/princeton-nlp/ProLong) + [How to Train Long-Context Language Models (Effectively)](https://arxiv.org/pdf/2410.02660)
* [Arctic Long Sequence Training (ALST): Scalable And Efficient Training For Multi-Million Token Sequences](https://www.snowflake.com/en/engineering-blog/arctic-long-sequence-training-multi-million-token-ai/) + [Paper](https://arxiv.org/pdf/2506.13996)
* [HELMET: How to Evaluate Long-Context Language Models Effectively and Thoroughly](https://arxiv.org/pdf/2410.02694)
